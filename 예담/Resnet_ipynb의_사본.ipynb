{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mylovepyd03/26-1-Lab-Intern/blob/main/Resnet_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ae2f29",
      "metadata": {
        "id": "c6ae2f29"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8cb4e241",
      "metadata": {
        "id": "8cb4e241"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "05dc005b",
      "metadata": {
        "id": "05dc005b"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):#conv2개\n",
        "    expansion_factor = 1\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
        "      super(BasicBlock, self).__init__() #상속nn module 기능세팅\n",
        "\n",
        "       #층설계\n",
        "      self.stride = stride\n",
        "      self.in_channels= in_channels\n",
        "      self.out_channels = out_channels\n",
        "\n",
        "        # 첫 번째 레이어: 이미지 크기를 stride에 맞춰 조절\n",
        "      self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(out_channels) #배치정규화가 나오므로 bias 를 false로 설정\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 두 번째 레이어: 채널과 크기 유지\n",
        "      self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 지름길(Shortcut): 입력 x가 출력과 모양이 다를 때(stride가 있거나 채널이 바뀔 때) 크기를 맞춰줌\n",
        "      self.shortcut = nn.Sequential()\n",
        "      if stride != 1 or in_channels != out_channels: #입력과 출력의 구격이 다를경우\n",
        "          self.shortcut = nn.Sequential(\n",
        "              nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "              nn.BatchNorm2d(out_channels) #skip하는거, 그대로 데이터 데려감 이때 규격맞추어주기 위함ㅊ채널,규격 다)\n",
        "          )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "\n",
        "        identity = x #원래 데이터 복사:입력정보x를 받아와서 identuty변수에 따로 빼둔다.\n",
        "\n",
        "        # 2. 메인 경로 연산 (Conv -> BN -> ReLU -> Conv -> BN) #데이터가공\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # 3. 지름길 더하기 (잔차 연결)\n",
        "        # 만약 크기가 다르다면 shortcut()을 거쳐서 크기를 맞춘 뒤 더함\n",
        "        out += self.shortcut(identity) #가공 결과에 원래 데이터를 정해서 정보의소실을 막는것\n",
        "\n",
        "        # 4. 마지막 ReLU\n",
        "        out = self.relu(out)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6abd7465",
      "metadata": {
        "id": "6abd7465"
      },
      "outputs": [],
      "source": [
        "class BottleNeck(nn.Module):\n",
        "#conv3개\n",
        "\n",
        "    expansion_factor = 4 # 표준 레즈넷크기 반영\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.in_channels= in_channels\n",
        "        # 1. 첫 번째 층: 1x1 Conv (채널을 좁게 줄여서 계산량을 줄임) 256번만 계산하면돼서 훨씬 계산이 빨라서 잘줄여줌\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 2. 두 번째 층: 3x3 Conv (좁아진 채널 상태로 특징 추출)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # 3. 세 번째 층: 1x1 Conv (채널을 다시 넓게 확장 - expansion_factor 배)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion_factor,\n",
        "                               kernel_size=1, bias=False)#줄어든값을 다시 늘려주는 역할 ,(64x4)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion_factor)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 4. 지름길(Shortcut): 입력 x와 출력의 모양이 다를 때 맞춰줌\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion_factor:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion_factor,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion_factor)\n",
        "            )\n",
        "\n",
        "\n",
        "    def forward(self, x:Tensor) -> Tensor: #실제 행동\n",
        "\n",
        "        identity = x\n",
        "\n",
        "        # 첫 번째: 1x1 Conv로 채널 압축 (다이어트)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # 두 번째: 3x3 Conv로 진짜 공부 (특징 추출)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # 세 번째: 1x1 Conv로 채널 확장 (다시 뻥튀기)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        # 3. 마법의 합치기 (Shortcut Connection)\n",
        "        # 공부한 결과(out)에 아까 챙겨둔 원래 데이터(identity)를 더합니다.\n",
        "       #규격은 알아서 아까위에 코드에서 맞춤 (init)\n",
        "        out += self.shortcut(identity)\n",
        "\n",
        "        # 마지막으로 ReLU를 한 번 더 거치며 마무리!\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "674ce3ba",
      "metadata": {
        "id": "674ce3ba"
      },
      "outputs": [],
      "source": [
        "#코드내가짠거\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        self.block= block\n",
        "        self.num_blocks = num_blocks\n",
        "        self.num_classes = num_classes\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64 # 초기 채널 설정\n",
        "\n",
        "        # 1. 첫 번째 Conv 레이어: 입력 이미지(3채널)를 처리\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 2. 4개의 ResNet Layer (Stage) 생성\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        #stride를 크게 할수록 정보손실을 막기위해 채널의 수를 늘림\n",
        "\n",
        "        # 3. 출력 레이어 (Global Average Pooling + Fully Connected)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion_factor, num_classes)\n",
        "\n",
        "        self._init_layer()\n",
        "      #블록 연결\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion_factor\n",
        "        return nn.Sequential(*layers)\n",
        "       #세팅 최적화 가중치 초기값 설정하고,  데이터 정규화 해주는 장치들을 아무것도 건드리지 않는 상태로 맞춰주기\n",
        "    def _init_layer(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # 초기 레이어 통과\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # 각 Stage 통과\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # 분류 레이어 통과\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x) #결과판단\n",
        "\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4cc02570",
      "metadata": {
        "id": "4cc02570"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def resnet18(self, num_classes=10): # 기본값은 10으로 두되\n",
        "      res18 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "      return res18\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet34(self):\n",
        "        res34= ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "        return res34\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet50(self):\n",
        "        res50= ResNet(BottleNeck, [3, 4, 6, 3])\n",
        "\n",
        "        return res50\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet101(self):\n",
        "        res101= ResNet(BottleNeck, [3, 4, 23, 3])\n",
        "\n",
        "        return res101\n",
        "        # 여기에 코드를 작성해주세요\n",
        "\n",
        "    def resnet152(self):\n",
        "        res152= ResNet(BottleNeck, [3, 8, 36, 3])\n",
        "        return res152\n",
        "        # 여기에 코드를 작성해주세요\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a305a18b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a305a18b",
        "outputId": "6107aaf5-d2c5-4876-af98-e18f45ac4265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "model = Model().resnet152()\n",
        "y = model(torch.randn(1, 3, 224, 224))\n",
        "print(y.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# hyper-parameters\n",
        "learning_rate = 0.01\n",
        "weight_decay = 1e-4\n",
        "momentum = 0.9\n",
        "batch_size = 128\n",
        "num_epochs = 1"
      ],
      "metadata": {
        "id": "ExS5XZRgGbFJ"
      },
      "id": "ExS5XZRgGbFJ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_transform(train_mean, train_std, test_mean, test_std):\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(train_mean, train_std),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.Normalize(test_mean, test_std),\n",
        "    ])\n",
        "\n",
        "    return train_transform, test_transform\n",
        "\n",
        "def do_mean_std(train_data, test_data):\n",
        "    train_mean_rgb = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_data]\n",
        "    train_std_rgb  = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_data]\n",
        "\n",
        "    test_mean_rgb = [np.mean(x.numpy(), axis=(1,2)) for x, _ in test_data]\n",
        "    test_std_rgb  = [np.std(x.numpy(), axis=(1,2)) for x, _ in test_data]\n",
        "\n",
        "    train_mean = np.mean(train_mean_rgb, axis=0).tolist()\n",
        "    train_std  = np.mean(train_std_rgb, axis=0).tolist()\n",
        "    test_mean  = np.mean(test_mean_rgb, axis=0).tolist()\n",
        "    test_std   = np.mean(test_std_rgb, axis=0).tolist()\n",
        "\n",
        "    return train_mean, train_std, test_mean, test_std\n"
      ],
      "metadata": {
        "id": "MczBOjbbGo9G"
      },
      "id": "MczBOjbbGo9G",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#내가수정\n",
        "def get_dataloader(train_data, test_data, batch_size=64):\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "    # 여기에 코드를 작성해주세요\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "fVkF5w-SGrf2"
      },
      "id": "fVkF5w-SGrf2",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.STL10(\n",
        "    root='./data',\n",
        "    split='train',\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor() #사진(이미지 파일)을 AI가 계산할 수 있는 숫자(Tensor) 형태로 바로 바꿔서 가져와라는 뜻\n",
        ")\n",
        "\n",
        "test_data = datasets.STL10(\n",
        "    root='./data',\n",
        "    split='test',\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n"
      ],
      "metadata": {
        "id": "o-7rxnxwGsjU"
      },
      "id": "o-7rxnxwGsjU",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mean, train_std, test_mean, test_std = do_mean_std(train_data, test_data)\n",
        "train_transform, test_transform = do_transform(train_mean, train_std, test_mean, test_std)\n",
        "\n",
        "train_data.transform = train_transform\n",
        "test_data.transform  = test_transform\n",
        "\n",
        "train_loader, test_loader = get_dataloader(train_data, test_data)"
      ],
      "metadata": {
        "id": "LEmzcJI2GtyS"
      },
      "id": "LEmzcJI2GtyS",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3xDfRb-Gv5M",
        "outputId": "86e9af1c-f333-41e0-ab99-6a59be2e128a"
      },
      "id": "I3xDfRb-Gv5M",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().resnet152().to(device)\n",
        "learning_rate = 0.001  # 공부 속도 (너무 크면 성적이 튀고, 작으면 너무 느림)\n",
        "weight_decay = 1e-4    # 과적합 방지\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
        "# 학습률 조절\n"
      ],
      "metadata": {
        "id": "U0U94osIGxKd"
      },
      "id": "U0U94osIGxKd",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # -------- Train --------\n",
        "    model.train()\n",
        "    correct, count = 0, 0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for step, (images, labels) in enumerate(train_loader, start=1):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss= criterion(model(images), labels)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        count += len(labels)\n",
        "        correct += (model(images).argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        print(\n",
        "            f\"[Train] Epoch {epoch} \"\n",
        "            f\"Step {step}/{len(train_loader)} \"\n",
        "            f\"Acc {(correct/count)*100:.2f}% \"\n",
        "            f\"Loss {(train_loss/count):.4f}\"\n",
        "        )\n",
        "\n",
        "    # -------- Validation --------\n",
        "    model.eval()\n",
        "    correct, count = 0, 0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (images, labels) in enumerate(test_loader, start=1):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            #테스트용 예측과 오차 계산\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            count += len(labels)\n",
        "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "            print(\n",
        "                f\"[Valid] Step {step}/{len(test_loader)} \"\n",
        "                f\"Acc {(correct/count)*100:.2f}% \"\n",
        "                f\"Loss {(valid_loss/count):.4f}\"\n",
        "            )\n",
        "\n",
        "    scheduler.step(valid_loss) ## 성적이 안 좋으면 학습률을 낮추는것"
      ],
      "metadata": {
        "id": "B-MYOufzGyMx"
      },
      "id": "B-MYOufzGyMx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
